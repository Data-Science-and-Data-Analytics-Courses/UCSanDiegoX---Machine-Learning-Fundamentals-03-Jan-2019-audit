{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bivariate_Gaussian.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit/blob/master/Week%2002%20Generative%20Modeling%20I/bivariate-gaussian/Bivariate_Gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "t4rKjjcv9BAj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments with the bivariate Gaussian"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UdDQ4H0VmPpJ"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone remote"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cXqTKogHXEr9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "68495994-9a6b-4dcd-8108-43944c90d469"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "URL = \"https://github.com/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit\"\n",
        "NBDIR = \"Week 02 Generative Modeling I/bivariate-gaussian\"\n",
        "\n",
        "def clone(url, dpath=\".\", branch=\"master\"):\n",
        "  \"\"\"\n",
        "  Clone remote branch from url into dpath\n",
        "  branch not provided: clone all branches\n",
        "  \"\"\"\n",
        "\n",
        "  url = url.strip(\"/\")\n",
        "  rname = os.path.basename(url)\n",
        "  rpath = os.path.join(dpath, rname)\n",
        "\n",
        "  # Raise error if dpath inside existing repository\n",
        "  is_out = !git -C \"$dpath\" rev-parse\n",
        "  if not is_out: # inside repository\n",
        "    raise ValueError(\"Can't clone into existing repository\")\n",
        "  \n",
        "  # Clone specific branch\n",
        "  if branch:\n",
        "    !git clone --single-branch --branch \"$branch\" \"$url\" \"$rpath\"\n",
        "  # Clone all branches\n",
        "  else:\n",
        "    !git clone \"$url\" \"$rpath\"\n",
        "  os.chdir(rpath)\n",
        "  \n",
        "  bname = !git rev-parse --abbrev-ref HEAD\n",
        "  print(\"Current\")\n",
        "  print(\"{branch}\\t{directory}\".format(branch=bname, directory=os.getcwd()))\n",
        "  \n",
        "clone(URL)\n",
        "%run .Importable.ipynb\n",
        "%cd \"$NBDIR\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into './UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 239 (delta 63), reused 4 (delta 1), pack-reused 111\u001b[K\n",
            "Receiving objects: 100% (239/239), 2.55 MiB | 5.99 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Current\n",
            "['master']\t/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type='text/css'>\n",
              ".hll { background-color: #ffffcc }\n",
              ".c { color: #408080; font-style: italic } /* Comment */\n",
              ".err { border: 1px solid #FF0000 } /* Error */\n",
              ".k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".o { color: #666666 } /* Operator */\n",
              ".ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".gd { color: #A00000 } /* Generic.Deleted */\n",
              ".ge { font-style: italic } /* Generic.Emph */\n",
              ".gr { color: #FF0000 } /* Generic.Error */\n",
              ".gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".gi { color: #00A000 } /* Generic.Inserted */\n",
              ".go { color: #888888 } /* Generic.Output */\n",
              ".gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".gs { font-weight: bold } /* Generic.Strong */\n",
              ".gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".gt { color: #0044DD } /* Generic.Traceback */\n",
              ".kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".kt { color: #B00040 } /* Keyword.Type */\n",
              ".m { color: #666666 } /* Literal.Number */\n",
              ".s { color: #BA2121 } /* Literal.String */\n",
              ".na { color: #7D9029 } /* Name.Attribute */\n",
              ".nb { color: #008000 } /* Name.Builtin */\n",
              ".nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".no { color: #880000 } /* Name.Constant */\n",
              ".nd { color: #AA22FF } /* Name.Decorator */\n",
              ".ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".nf { color: #0000FF } /* Name.Function */\n",
              ".nl { color: #A0A000 } /* Name.Label */\n",
              ".nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".nv { color: #19177C } /* Name.Variable */\n",
              ".ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".mf { color: #666666 } /* Literal.Number.Float */\n",
              ".mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".sx { color: #008000 } /* Literal.String.Other */\n",
              ".sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".vc { color: #19177C } /* Name.Variable.Class */\n",
              ".vg { color: #19177C } /* Name.Variable.Global */\n",
              ".vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".il { color: #666666 } /* Literal.Number.Integer.Long */\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit/Week 02 Generative Modeling I/bivariate-gaussian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nDuguT5G9BAm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll get a feel for the two-dimensional Gaussian by varying the covariance matrix, drawing random samples from the resulting distribution, and plotting contour lines of the density."
      ]
    },
    {
      "metadata": {
        "id": "elXoDFuc9BAo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We begin, as always, by loading in standard packages."
      ]
    },
    {
      "metadata": {
        "id": "YePRyx2W9BAp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "# installing packages for interactive graphs\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mHy0hda09BAs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function **bivariate_plot** takes as input three parameters that uniquely specify a 2x2 covariance matrix:\n",
        "* `var1`, the variance of the first feature, `x1`\n",
        "* `var2`, the variance of the second feature, `x2`\n",
        "* `corr`, the correlation between `x1` and `x2`\n",
        "\n",
        "It then depicts a 2-d Gaussian whose mean is the origin and whose covariance matrix is given by these parameters. The display consists of 100 points randomly sampled from the Gaussian, as well as three representative contour lines of the density.\n",
        "\n",
        "The first line below, **interact_manual**, sets up an interactive widget that allows you to specify the parameters to **bivariate_plot** using sliders, and provides a button to execute the function."
      ]
    },
    {
      "metadata": {
        "id": "UbTG2Y-M9BAu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@interact_manual(var1 = (1,9), var2 = (1,9), corr=(-0.95,0.95,0.05))\n",
        "def bivariate_plot(var1, var2, corr):\n",
        "    #\n",
        "    # Set parameters of Gaussian\n",
        "    mu = [0,0]\n",
        "    covariance = corr * np.sqrt(var1) * np.sqrt(var2)\n",
        "    sigma = [[var1,covariance], [covariance,var2]]\n",
        "    np.set_printoptions(precision=2)\n",
        "    print \"Covariance matrix:\"\n",
        "    print np.around(sigma, decimals=2)\n",
        "    #\n",
        "    # Draw samples from the distribution\n",
        "    n = 100\n",
        "    x = np.random.multivariate_normal(mu,sigma,size=n)\n",
        "    #\n",
        "    # Set up a plot for the samples and the density contours\n",
        "    lim = 10.0\n",
        "    plt.xlim(-lim, lim) # limit along x1-axis\n",
        "    plt.ylim(-lim, lim) # limit along x2-axis    \n",
        "    plt.axes().set_aspect('equal', 'datalim')\n",
        "    #\n",
        "    # Plot the sampled points as blue dots\n",
        "    plt.plot(x[:,0], x[:,1], 'bo')\n",
        "    #\n",
        "    # To display contour lines, first define a fine grid\n",
        "    res = 200\n",
        "    xg = np.linspace(-lim, lim, res)\n",
        "    yg = np.linspace(-lim, lim, res)\n",
        "    z = np.zeros((res,res))\n",
        "    # Compute the density at each grid point\n",
        "    rv = multivariate_normal(mean=mu, cov=sigma)\n",
        "    for i in range(0,res):\n",
        "        for j in range(0,res):\n",
        "            z[j,i] = rv.logpdf([xg[i], yg[j]]) \n",
        "    sign, logdet = np.linalg.slogdet(sigma)\n",
        "    normalizer = -0.5 * (2 * np.log(6.28) + sign * logdet)\n",
        "    # Now plot a few contour lines of the density\n",
        "    for offset in range(1,4):\n",
        "        plt.contour(xg,yg,z, levels=[normalizer - offset], colors='r', linewidths=2.0, linestyles='solid')\n",
        "\n",
        "    # Finally, display\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMiAVfEF9BAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## <font color=\"magenta\">Quick exercise:</font>\n",
        "Experiment with the widget above to get a sense for how the different parameters influence the shape of the Gaussian. In particular, figure out the answers to the following questions.\n",
        "* Under what conditions does the Gaussian have contour lines that are perfect circles?\n",
        "* Under what conditions is the Gaussian tilted upwards?\n",
        "* Under what conditions is the Gaussian titled downwards?\n",
        "* Suppose the Gaussian has no tilt, and the contour lines are stretched vertically, so that the vertical stretch is twice the horizontal stretch. What can we conclude about the covariance matrix?\n",
        "\n",
        "*Note down the answers to these questions: you will enter them later, as part of this week's assignment.*"
      ]
    }
  ]
}
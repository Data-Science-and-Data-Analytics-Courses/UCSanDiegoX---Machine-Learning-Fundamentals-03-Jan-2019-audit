{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "perceptron_at_work.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit/blob/master/Week%2006%20Linear%20Classification/perceptron_at_work/perceptron_at_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uoFEUETLODdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Perceptron algorithm at work"
      ]
    },
    {
      "metadata": {
        "id": "Gfo0BZ0oODdy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will look in detail at the Perceptron algorithm for learning a linear classifier in the case of binary labels."
      ]
    },
    {
      "metadata": {
        "id": "2yII5ilWOI55",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone remote"
      ]
    },
    {
      "metadata": {
        "id": "7RXDIvezOJD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "d5461cde-db98-47ed-c3ed-b60c7ba2f1d2"
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "URL = \"https://github.com/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit\"\n",
        "NBDIR = \"Week 06 Linear Classification/perceptron_at_work\"\n",
        "\n",
        "def clone(url, dest=\".\", branch=\"master\", reloc=True):\n",
        "  \"\"\"\n",
        "  Clone remote branch from url into dest\n",
        "  branch not provided: clone all branches\n",
        "  reloc is True: relocate to repository\n",
        "  \"\"\"\n",
        "\n",
        "  url = url.strip(\" /\")\n",
        "  repo = Path(dest, os.path.basename(url)).resolve()\n",
        "\n",
        "  # dest must not be inside existing repository\n",
        "  is_out = !git -C \"$dest\" rev-parse\n",
        "  if not is_out: # inside repository\n",
        "    raise ValueError(\"Can't clone into existing repository\")\n",
        "  \n",
        "  # Clone\n",
        "  p = repo.as_posix()\n",
        "  if branch: # specific branch\n",
        "    !git clone --single-branch \"$url\" -b \"$branch\" \"$p\"\n",
        "  else: # all branches\n",
        "    !git clone \"$url\" \"$p\"\n",
        "  \n",
        "  # Relocate\n",
        "  if reloc:\n",
        "    %cd \"$repo\"\n",
        "\n",
        "  return repo.as_posix()\n",
        "\n",
        "REPO = clone(URL)\n",
        "%run .Importable.ipynb\n",
        "sys.path.append(REPO)\n",
        "%cd \"$NBDIR\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd672d2a5760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mREPO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'run .Importable.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-dd672d2a5760>\u001b[0m in \u001b[0;36mclone\u001b[0;34m(url, dest, branch, reloc)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" /\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mrepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# dest must not be inside existing repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pathlib.pyc\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         Windows).\n\u001b[1;32m   1033\u001b[0m         \"\"\"\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;31m# No symlink resolution => for consistency, raise an error if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pathlib.pyc\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# which are symlinks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_reserved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pathlib.pyc\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(path, rest)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;31m# Resolve the symbolic link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEINVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pathlib.pyc\u001b[0m in \u001b[0;36mreadlink\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;31m# Helper for resolve()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YIGClxGSODd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. The algorithm"
      ]
    },
    {
      "metadata": {
        "id": "NKcRt7MhODd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This first procedure, **evaluate_classifier**, takes as input the parameters of a linear classifier (`w,b`) as well as a data point (`x`) and returns the prediction of that classifier at `x`.\n",
        "\n",
        "The prediction is:\n",
        "* `1`  if `w.x+b > 0`\n",
        "* `0`  if `w.x+b = 0`\n",
        "* `-1` if `w.x+b < -1`"
      ]
    },
    {
      "metadata": {
        "id": "mjO5Wg_zODd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(w,b,x):\n",
        "    if (np.dot(w,x) + b) > 0:\n",
        "        return 1\n",
        "    if (np.dot(w,x) + b) <= 0:\n",
        "        return -1\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGRlXf0vODeD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is the Perceptron training procedure. It is invoked as follows:\n",
        "* `w,b,converged = train_perceptron(x,y,n_iters)`\n",
        "\n",
        "where\n",
        "* `x`: n-by-d numpy array with n data points, each d-dimensional\n",
        "* `y`: n-dimensional numpy array with the labels (each 1 or -1)\n",
        "* `n_iters`: the training procedure will run through the data at most this many times (default: 100)\n",
        "* `w,b`: parameters for the final linear classifier\n",
        "* `converged`: flag (True/False) indicating whether the algorithm converged within the prescribed number of iterations\n",
        "\n",
        "If the data is not linearly separable, then the training procedure will not converge."
      ]
    },
    {
      "metadata": {
        "id": "igRe8r-3ODeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_perceptron(x,y,n_iters=100):\n",
        "    n,d = x.shape\n",
        "    w = np.zeros((d,))\n",
        "    b = 0\n",
        "    done = False\n",
        "    converged = True\n",
        "    iters = 0\n",
        "    np.random.seed(None)\n",
        "    while not(done):\n",
        "        done = True\n",
        "        I = np.random.permutation(n)\n",
        "        for i in range(n):\n",
        "            j = I[i]\n",
        "            if (evaluate_classifier(w,b,x[j,:]) != y[j]):\n",
        "                w = w + y[j] * x[j,:]\n",
        "                b = b + y[j]\n",
        "                done = False\n",
        "        iters = iters + 1\n",
        "        if iters > n_iters:\n",
        "            done = True\n",
        "            converged = False\n",
        "    if converged:\n",
        "        print \"Perceptron algorithm: iterations until convergence: \", iters\n",
        "    else:\n",
        "        print \"Perceptron algorithm: did not converge within the specified number of iterations\"\n",
        "    return w, b, converged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndYyFIfpODeK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Experiments with the Perceptron"
      ]
    },
    {
      "metadata": {
        "id": "AzB48J3tODeM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We start with standard includes."
      ]
    },
    {
      "metadata": {
        "id": "557PgfH1ODeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rc('xtick', labelsize=14) \n",
        "matplotlib.rc('ytick', labelsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EIwHol7UODeS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The directory containing this notebook should also contain the two-dimensional data files, `data_1.txt` and `data_2.txt`. These files contain one data point per line, along with a label, like:\n",
        "* `3 8 1` (meaning that point `x=(3,8)` has label `y=1`)\n",
        "\n",
        "The next procedure, **run_perceptron**, loads one of these data sets, learns a linear classifier using the Perceptron algorithm, and then displays the data as well as the boundary."
      ]
    },
    {
      "metadata": {
        "id": "MKkcS15UODeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_perceptron(datafile):\n",
        "    data = np.loadtxt(datafile)\n",
        "    n,d = data.shape\n",
        "    # Create training set x and labels y\n",
        "    x = data[:,0:2]\n",
        "    y = data[:,2]\n",
        "    # Run the Perceptron algorithm for at most 100 iterations\n",
        "    w,b,converged = train_perceptron(x,y,100)\n",
        "    # Determine the x1- and x2- limits of the plot\n",
        "    x1min = min(x[:,0]) - 1\n",
        "    x1max = max(x[:,0]) + 1\n",
        "    x2min = min(x[:,1]) - 1\n",
        "    x2max = max(x[:,1]) + 1\n",
        "    plt.xlim(x1min,x1max)\n",
        "    plt.ylim(x2min,x2max)\n",
        "    # Plot the data points\n",
        "    plt.plot(x[(y==1),0], x[(y==1),1], 'ro')\n",
        "    plt.plot(x[(y==-1),0], x[(y==-1),1], 'k^')\n",
        "    # Construct a grid of points at which to evaluate the classifier\n",
        "    if converged:\n",
        "        grid_spacing = 0.05\n",
        "        xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, grid_spacing), np.arange(x2min, x2max, grid_spacing))\n",
        "        grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "        Z = np.array([evaluate_classifier(w,b,pt) for pt in grid])\n",
        "        # Show the classifier's boundary using a color plot\n",
        "        Z = Z.reshape(xx1.shape)\n",
        "        plt.pcolormesh(xx1, xx2, Z, cmap=plt.cm.PRGn, vmin=-3, vmax=3)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1y2CPxFODeX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's run this on `data_1.txt`. Try running it a few times; you should get slightly different outcomes, because of the randomization in the learning procedure."
      ]
    },
    {
      "metadata": {
        "id": "0Y6emFqmODeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_perceptron('data_1.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpcSMiEZODec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And now, let's try running it on `data_2.txt`. *What's going on here?*"
      ]
    },
    {
      "metadata": {
        "id": "GVSB3pu_ODee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_perceptron('data_2.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d0Q0EtgFODeg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. For you to do"
      ]
    },
    {
      "metadata": {
        "id": "vGuacg9qODeh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<font color=\"magenta\">Design a data set</font> with the following specifications:\n",
        "* there are just two data points, with labels -1 and 1\n",
        "* the two points are distinct, with coordinate values in the range [-1,1]\n",
        "* the Perceptron algorithm requires more than 1000 iterations to converge"
      ]
    },
    {
      "metadata": {
        "id": "jDHYUO4NODej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
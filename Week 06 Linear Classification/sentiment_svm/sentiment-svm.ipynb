{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-svm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit/blob/master/Week%2006%20Linear%20Classification/sentiment_svm/sentiment-svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CigeLnu0P0hD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis with support vector machines\n",
        "\n",
        "In this notebook, we will revisit a learning task that we encountered earlier in the course: predicting the *sentiment* (positive or negative) of a single sentence taken from a review of a movie, restaurant, or product. The data set consists of 3000 labeled sentences, which we divide into a training set of size 2500 and a test set of size 500. Previously we found a logistic regression classifier. Today we will use a support vector machine.\n",
        "\n",
        "Before starting on this notebook, make sure the folder `sentiment_labelled_sentences` (containing the data file `full_set.txt`) is in the same directory. Recall that the data can be downloaded from https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences. "
      ]
    },
    {
      "metadata": {
        "id": "D9lDxD0mP7uS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone remote"
      ]
    },
    {
      "metadata": {
        "id": "PIG0_CZdP73I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b51a0487-87bf-4267-ba95-6d7ca44b9223"
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "URL = \"https://github.com/Data-Science-and-Data-Analytics-Courses/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit\"\n",
        "NBDIR = \"Week 06 Linear Classification/sentiment_svm\"\n",
        "\n",
        "def clone(url, dest=\".\", branch=\"master\", reloc=True):\n",
        "  \"\"\"\n",
        "  Clone remote branch from url into dest\n",
        "  branch not provided: clone all branches\n",
        "  reloc is True: relocate to repository\n",
        "  \"\"\"\n",
        "\n",
        "  url = url.strip(\" /\")\n",
        "  repo = Path(dest, os.path.basename(url)).resolve()\n",
        "\n",
        "  # dest must not be inside existing repository\n",
        "  is_out = !git -C \"$dest\" rev-parse\n",
        "  if not is_out: # inside repository\n",
        "    raise ValueError(\"Can't clone into existing repository\")\n",
        "  \n",
        "  # Clone\n",
        "  p = repo.as_posix()\n",
        "  if branch: # specific branch\n",
        "    !git clone --single-branch \"$url\" -b \"$branch\" \"$p\"\n",
        "  else: # all branches\n",
        "    !git clone \"$url\" \"$p\"\n",
        "  \n",
        "  # Relocate\n",
        "  if reloc:\n",
        "    %cd \"$repo\"\n",
        "\n",
        "  return repo.as_posix()\n",
        "\n",
        "REPO = clone(URL)\n",
        "%run .Importable.ipynb\n",
        "sys.path.append(REPO)\n",
        "%cd \"$NBDIR\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 951 (delta 34), reused 0 (delta 0), pack-reused 879\u001b[K\n",
            "Receiving objects: 100% (951/951), 3.42 MiB | 3.02 MiB/s, done.\n",
            "Resolving deltas: 100% (483/483), done.\n",
            "/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type='text/css'>\n",
              ".hll { background-color: #ffffcc }\n",
              ".c { color: #408080; font-style: italic } /* Comment */\n",
              ".err { border: 1px solid #FF0000 } /* Error */\n",
              ".k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".o { color: #666666 } /* Operator */\n",
              ".ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".gd { color: #A00000 } /* Generic.Deleted */\n",
              ".ge { font-style: italic } /* Generic.Emph */\n",
              ".gr { color: #FF0000 } /* Generic.Error */\n",
              ".gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".gi { color: #00A000 } /* Generic.Inserted */\n",
              ".go { color: #888888 } /* Generic.Output */\n",
              ".gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".gs { font-weight: bold } /* Generic.Strong */\n",
              ".gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".gt { color: #0044DD } /* Generic.Traceback */\n",
              ".kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".kt { color: #B00040 } /* Keyword.Type */\n",
              ".m { color: #666666 } /* Literal.Number */\n",
              ".s { color: #BA2121 } /* Literal.String */\n",
              ".na { color: #7D9029 } /* Name.Attribute */\n",
              ".nb { color: #008000 } /* Name.Builtin */\n",
              ".nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".no { color: #880000 } /* Name.Constant */\n",
              ".nd { color: #AA22FF } /* Name.Decorator */\n",
              ".ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".nf { color: #0000FF } /* Name.Function */\n",
              ".nl { color: #A0A000 } /* Name.Label */\n",
              ".nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".nv { color: #19177C } /* Name.Variable */\n",
              ".ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".mf { color: #666666 } /* Literal.Number.Float */\n",
              ".mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".sx { color: #008000 } /* Literal.String.Other */\n",
              ".sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".vc { color: #19177C } /* Name.Variable.Class */\n",
              ".vg { color: #19177C } /* Name.Variable.Global */\n",
              ".vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".il { color: #666666 } /* Literal.Number.Integer.Long */\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/UCSanDiegoX---Machine-Learning-Fundamentals-03-Jan-2019-audit/Week 06 Linear Classification/sentiment_svm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WF3W2CB3P0hH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Loading and preprocessing the data\n",
        " \n",
        "Here we follow exactly the same steps as we did earlier."
      ]
    },
    {
      "metadata": {
        "id": "BR8PaPv9P0hJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rc('xtick', labelsize=14) \n",
        "matplotlib.rc('ytick', labelsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7DYOaKBP0hM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e643ad1-6682-4065-bccd-9ad00be21b59"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Reuse dataset\n",
        "datapath = Path(REPO, \"Week 04 Linear Regression and Probability Estimation/sentiment-logistic-regression/sentiment_labelled_sentences/full_set.txt\")\n",
        "## Read in the data set.\n",
        "with open(datapath) as f:\n",
        "    content = f.readlines()\n",
        "    \n",
        "## Remove leading and trailing white space\n",
        "content = [x.strip() for x in content]\n",
        "\n",
        "## Separate the sentences from the labels\n",
        "sentences = [x.split(\"\\t\")[0] for x in content]\n",
        "labels = [x.split(\"\\t\")[1] for x in content]\n",
        "\n",
        "## Transform the labels from '0 v.s. 1' to '-1 v.s. 1'\n",
        "y = np.array(labels, dtype='int8')\n",
        "y = 2*y - 1\n",
        "\n",
        "## full_remove takes a string x and a list of characters removal_list \n",
        "## returns x with all the characters in removal_list replaced by ' '\n",
        "def full_remove(x, removal_list):\n",
        "    for w in removal_list:\n",
        "        x = x.replace(w, ' ')\n",
        "    return x\n",
        "\n",
        "## Remove digits\n",
        "digits = [str(x) for x in range(10)]\n",
        "digit_less = [full_remove(x, digits) for x in sentences]\n",
        "\n",
        "## Remove punctuation\n",
        "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]\n",
        "\n",
        "## Make everything lower-case\n",
        "sents_lower = [x.lower() for x in punc_less]\n",
        "\n",
        "## Define our stop words\n",
        "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from'])\n",
        "\n",
        "## Remove stop words\n",
        "sents_split = [x.split() for x in sents_lower]\n",
        "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]\n",
        "\n",
        "## Transform to bag of words representation.\n",
        "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 4500)\n",
        "data_features = vectorizer.fit_transform(sents_processed)\n",
        "\n",
        "## Append '1' to the end of each vector.\n",
        "data_mat = data_features.toarray()\n",
        "\n",
        "## Split the data into testing and training sets\n",
        "np.random.seed(0)\n",
        "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False))\n",
        "train_inds = list(set(range(len(labels))) - set(test_inds))\n",
        "\n",
        "train_data = data_mat[train_inds,]\n",
        "train_labels = y[train_inds]\n",
        "\n",
        "test_data = data_mat[test_inds,]\n",
        "test_labels = y[test_inds]\n",
        "\n",
        "print(\"train data: \", train_data.shape)\n",
        "print(\"test data: \", test_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data:  (2500, 4500)\n",
            "test data:  (500, 4500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BjHlWWEWP0hQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Fitting a support vector machine to the data\n",
        "\n",
        "In support vector machines, we are given a set of examples $(x_1, y_1), \\ldots, (x_n, y_n)$ and we want to find a weight vector $w \\in \\mathbb{R}^d$ that solves the following optimization problem:\n",
        "\n",
        "$$ \\min_{w \\in \\mathbb{R}^d} \\| w \\|^2 + C \\sum_{i=1}^n \\xi_i $$\n",
        "$$ \\text{subject to } y_i \\langle w, x_i \\rangle \\geq 1 - \\xi_i \\text{ for all } i=1,\\ldots, n$$\n",
        "\n",
        "`scikit-learn` provides an SVM solver that we will use. The following routine takes as input the constant `C` (from the above optimization problem) and returns the training and test error of the resulting SVM model. It is invoked as follows:\n",
        "\n",
        "* `training_error, test_error = fit_classifier(C)`\n",
        "\n",
        "The default value for parameter `C` is 1.0."
      ]
    },
    {
      "metadata": {
        "id": "uDjLe1A2P0hT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "def fit_classifier(C_value=1.0):\n",
        "    clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
        "    clf.fit(train_data,train_labels)\n",
        "    ## Get predictions on training data\n",
        "    train_preds = clf.predict(train_data)\n",
        "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels)\n",
        "    ## Get predictions on test data\n",
        "    test_preds = clf.predict(test_data)\n",
        "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
        "    ##\n",
        "    return train_error, test_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B8rpdlccP0hX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e1285b52-0a48-4114-ad23-10f0b5a153e2"
      },
      "cell_type": "code",
      "source": [
        "cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0]\n",
        "for c in cvals:\n",
        "    train_error, test_error = fit_classifier(c)\n",
        "    print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error rate for C = 0.01: train 0.215 test 0.250\n",
            "Error rate for C = 0.10: train 0.074 test 0.174\n",
            "Error rate for C = 1.00: train 0.011 test 0.152\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Error rate for C = 10.00: train 0.002 test 0.188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Error rate for C = 100.00: train 0.002 test 0.200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Error rate for C = 1000.00: train 0.004 test 0.214\n",
            "Error rate for C = 10000.00: train 0.002 test 0.202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "W2Ip_MXhP0ha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluating C by k-fold cross-validation\n",
        "\n",
        "As we can see, the choice of `C` has a very significant effect on the performance of the SVM classifier. We were able to assess this because we have a separate test set. In general, however, this is a luxury we won't possess. How can we choose `C` based only on the training set?\n",
        "\n",
        "A reasonable way to estimate the error associated with a specific value of `C` is by **`k-fold cross validation`**:\n",
        "* Partition the training set `S` into `k` equal-sized sized subsets `S_1, S_2, ..., S_k`.\n",
        "* For `i=1,2,...,k`, train a classifier with parameter `C` on `S - S_i` (all the training data except `S_i`) and test it on `S_i` to get error estimate `e_i`.\n",
        "* Average the errors: `(e_1 + ... + e_k)/k`\n",
        "\n",
        "The following procedure, **cross_validation_error**, does exactly this. It takes as input:\n",
        "* the training set `x,y`\n",
        "* the value of `C` to be evaluated\n",
        "* the integer `k`\n",
        "\n",
        "and it returns the estimated error of the classifier for that particular setting of `C`. <font color=\"magenta\">Look over the code carefully to understand exactly what it is doing.</font>"
      ]
    },
    {
      "metadata": {
        "id": "s8Ay2ZhpP0hb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cross_validation_error(x,y,C_value,k):\n",
        "    n = len(y)\n",
        "    ## Randomly shuffle indices\n",
        "    indices = np.random.permutation(n)\n",
        "    \n",
        "    ## Initialize error\n",
        "    err = 0.0\n",
        "    \n",
        "    ## Iterate over partitions\n",
        "    for i in range(k):\n",
        "        ## Partition indices\n",
        "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)]\n",
        "        train_indices = np.setdiff1d(indices, test_indices)\n",
        "        \n",
        "        ## Train classifier with parameter c\n",
        "        clf = svm.LinearSVC(C=C_value, loss='hinge')\n",
        "        clf.fit(x[train_indices], y[train_indices])\n",
        "        \n",
        "        ## Get predictions on test partition\n",
        "        preds = clf.predict(x[test_indices])\n",
        "        \n",
        "        ## Compute error\n",
        "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices)\n",
        "        \n",
        "    return err/k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtFJggETP0hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Picking a value of C"
      ]
    },
    {
      "metadata": {
        "id": "BG604GZOP0hf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The procedure **cross_validation_error** (above) evaluates a single candidate value of `C`. We need to use it repeatedly to identify a good `C`. \n",
        "\n",
        "<font color=\"magenta\">**For you to do:**</font> Write a function to choose `C`. It will be invoked as follows:\n",
        "\n",
        "* `c, err = choose_parameter(x,y,k)`\n",
        "\n",
        "where\n",
        "* `x,y` is the training data\n",
        "* `k` is the number of folds of cross-validation\n",
        "* `c` is chosen value of the parameter `C`\n",
        "* `err` is the cross-validation error estimate at `c`\n",
        "\n",
        "<font color=\"magenta\">Note:</font> This is a tricky business because a priori, even the order of magnitude of `C` is unknown. Should it be 0.0001 or 10000? You might want to think about trying multiple values that are arranged in a geometric progression (such as powers of ten). *In addition to returning a specific value of `C`, your function should **plot** the cross-validation errors for all the values of `C` it tried out (possibly using a log-scale for the `C`-axis).*"
      ]
    },
    {
      "metadata": {
        "id": "By_rYc93P0hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def choose_parameter(x,y,k, allerrors=False):\n",
        "    ### Your code here\n",
        "    C_values = 10.0**np.arange(-4, 5)\n",
        "    vcross = np.vectorize(cross_validation_error, excluded=[\"x\",\"y\",\"k\"])\n",
        "    errors = vcross(C_value=C_values, x=x, y=y, k=k)\n",
        "    \n",
        "    # Plot\n",
        "    plt.plot(np.log(C_values), errors, 'ro')\n",
        "    plt.xlabel(\"log(C)\")\n",
        "    plt.ylabel(\"error\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Best C\n",
        "    ix_best = errors.argmin()\n",
        "    C_best = C_values[ix_best]\n",
        "    err_min = errors[ix_best]\n",
        "    \n",
        "    if allerrors:\n",
        "      return C_best, err_min, np.log(C_values), errors\n",
        "    else:\n",
        "      return C_best, err_min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b2iR9WGDP0hl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's try out your routine!"
      ]
    },
    {
      "metadata": {
        "id": "5CYtTNqsP0ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1728
        },
        "outputId": "f4cf5efd-4c36-4058-f09c-38dace4b9efd"
      },
      "cell_type": "code",
      "source": [
        "c, err = choose_parameter(train_data, train_labels, 10)\n",
        "print(\"Choice of C: \", c)\n",
        "print(\"Cross-validation error estimate: \", err)\n",
        "## Train it and test it\n",
        "clf = svm.LinearSVC(C=c, loss='hinge')\n",
        "clf.fit(train_data, train_labels)\n",
        "preds = clf.predict(test_data)\n",
        "error = float(np.sum((preds > 0.0) != (test_labels > 0.0)))/len(test_labels)\n",
        "print(\"Test error: \", error)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Choice of C:  0.1\n",
            "Cross-validation error estimate:  0.19277108433734935\n",
            "Test error:  0.174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QB3i5HHTP0ht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<font color=\"magenta\">**For you to ponder:**</font> How does the plot of cross-validation errors for different `C` look? Is there clearly a trough in which the returned value of `C` falls? Does the plot provide some reassurance that the choice is reasonable?"
      ]
    },
    {
      "metadata": {
        "id": "jT3_YcthP0ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1796
        },
        "outputId": "a3e452b5-d49b-483e-9ccc-14f85670de39"
      },
      "cell_type": "code",
      "source": [
        "c, err, clogs, errors = choose_parameter(train_data, train_labels, 10, allerrors=True)\n",
        "falls = np.where(np.diff(clogs)*np.diff(errors) > 0) # indices where C and error fall together\n",
        "falls"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3, 4, 5, 6]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "CkamGECoem8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "397ad0a5-76e7-42cd-f2f9-c5bd673309e3"
      },
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "a= [1,1,0, 1,1,1, 0,0, 1]\n",
        "b=np.array(a)\n",
        "np.take(b, [[0, 1], [2, 3,4]])\n",
        "b[[[0,1]],[[5,6,8]]]\n",
        "[list(g) for k,g in groupby(a)]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-cb99ac3378c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[1;32m    157\u001b[0m            [5, 7]])\n\u001b[1;32m    158\u001b[0m     \"\"\"\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'take'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    }
  ]
}